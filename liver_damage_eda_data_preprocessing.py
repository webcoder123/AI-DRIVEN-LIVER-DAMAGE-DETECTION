# -*- coding: utf-8 -*-
"""Liver_Damage_EDA_Data_Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19f3XmenrpPFUfbWGnkkmHD2cirt_QoRH

üîç 1. Dataset Summary
Total images: Count the number of images.

Number of classes: How many categories do you want to classify?

Images per class: Check for class imbalance.
"""

from collections import Counter
import os

dataset_path = '/content/drive/MyDrive/New_liver_Dataset/Liver_Three_class_dataset'
class_counts = {cls: len(os.listdir(os.path.join(dataset_path, cls))) for cls in os.listdir(dataset_path)}
print(class_counts)

from google.colab import drive
drive.mount('/content/drive')

"""**EDA Steps for Histopathology Images**

#üîπ 4. Intensity Distribution

Plot pixel intensity histogram (R, G, B) for a few images.
"""

!pip install opencv-python
import cv2 # Import the cv2 module
import matplotlib.pyplot as plt
import os

def plot_intensity_histogram(img_path):
    img = cv2.imread(img_path)
    color = ('b', 'g', 'r')
    plt.figure(figsize=(6, 4))
    for i, col in enumerate(color):
        hist = cv2.calcHist([img], [i], None, [256], [0, 256])
        plt.plot(hist, color=col)
    plt.title("Pixel Intensity Distribution")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    plt.show()

# Define data_dir before using it
data_dir = '/content/drive/MyDrive/New_liver_Dataset/Liver_Three_class_dataset'  # Replace with your actual data directory

# Try with one image
sample_path = os.path.join(data_dir, 'HCC', os.listdir(os.path.join(data_dir, 'HCC'))[0])
plot_intensity_histogram(sample_path)

"""#üîπ 5. Color Mean & Standard Deviation (Per Class)
Compare brightness/contrast between different classes.
"""

import numpy as np
import cv2 # Added import for cv2
import os

def compute_color_stats_per_class(data_dir):
    stats = {}
    for cls in os.listdir(data_dir):
        img_paths = [os.path.join(data_dir, cls, img) for img in os.listdir(os.path.join(data_dir, cls))]
        means, stds = [], []
        for path in img_paths:
            img = cv2.imread(path)
            img = img.astype('float32') / 255.0
            means.append(np.mean(img, axis=(0, 1)))
            stds.append(np.std(img, axis=(0, 1)))
        stats[cls] = {
            "Mean": np.mean(means, axis=0),
            "Std Dev": np.mean(stds, axis=0)
        }
    return stats

# Use the correct data_dir variable
stats = compute_color_stats_per_class(data_dir)  # Changed "processed_dataset" to data_dir

for cls, val in stats.items():
    print(f"\nüìÅ Class: {cls}")
    print(f"üîπ Mean RGB: {val['Mean']}")
    print(f"üîπ Std Dev RGB: {val['Std Dev']}")

"""# üìÇ Optional: Export Summary Report

You can also write all stats to a CSV or TXT file if needed.
"""

with open("eda_summary.txt", "w") as f:
    for cls, val in stats.items():
        f.write(f"Class: {cls}\n")
        f.write(f"Mean RGB: {val['Mean']}\n")
        f.write(f"Std Dev RGB: {val['Std Dev']}\n\n")

"""(1)    **EDA**

‚úÖ **(1) Load Dataset**
"""

import os
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from scipy import stats

# Path to dataset folder
data_dir = '/content/drive/MyDrive/New_liver_Dataset/Liver_Three_class_dataset'

classes = os.listdir(data_dir)

# Create a dataframe to store metadata
image_data = []

for label in classes:
    class_dir = os.path.join(data_dir, label)
    for img_file in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_file)
        try:
            with Image.open(img_path) as img:
                width, height = img.size
                img_array = np.array(img.convert('L'))  # Convert to grayscale
                intensity_flat = img_array.flatten()
                mean_intensity = intensity_flat.mean()
                median_intensity = np.median(intensity_flat)
                mode_intensity = stats.mode(intensity_flat, axis=None, keepdims=False).mode
                aspect_ratio = width / height
                image_data.append([
                    img_file, label, width, height, aspect_ratio,
                    mean_intensity, median_intensity, mode_intensity
                ])
        except:
            print(f"Skipping corrupted image: {img_path}")

# Create DataFrame
df = pd.DataFrame(image_data, columns=[
    'Filename', 'Class', 'Width', 'Height', 'Aspect_Ratio',
    'Mean_Intensity', 'Median_Intensity', 'Mode_Intensity'
])

df.head()

df.describe()

"""**‚úÖ (2) EDA for Each Class**"""

# Class Distribution
plt.figure(figsize=(6,4))
sns.countplot(data=df, x='Class')
plt.title('Number of Images per Class')
plt.xlabel('Liver Tissue Class')
plt.ylabel('Image Count')
plt.show()

# Step 3: Undersample majority classes
# Get the minimum count of samples per class
min_count = df['Class'].value_counts().min()

# Undersample to balance the dataset
balanced_df = pd.concat([
    df[df['Class'] == cls].sample(min_count, random_state=42)
    for cls in df['Class'].unique()
])

# Check Balanced or Not
import os
import shutil
import random
from pathlib import Path

# Path to your original dataset
dataset_path = Path('/content/drive/MyDrive/New_liver_Dataset/Liver_Three_class_dataset')  # change if needed

# Count files in each class
class_counts = {folder.name: len(list(folder.glob('*'))) for folder in dataset_path.iterdir() if folder.is_dir()}
print("üìä Class Distribution BEFORE balancing:\n", class_counts)

# Get minimum count for balancing
min_count = min(class_counts.values())
print(f"\n‚öñÔ∏è Balancing all classes to {min_count} samples...")

# Output path for balanced data
balanced_path = Path('/content/balanced_dataset')
shutil.rmtree(balanced_path, ignore_errors=True)
balanced_path.mkdir(parents=True, exist_ok=True)

# Undersample and copy files
for class_name, count in class_counts.items():
    class_dir = dataset_path / class_name
    balanced_class_dir = balanced_path / class_name
    balanced_class_dir.mkdir(parents=True, exist_ok=True)

    # Randomly select min_count files
    selected_files = random.sample(list(class_dir.glob('*')), min_count)

    for file_path in selected_files:
        shutil.copy(file_path, balanced_class_dir)

# Check new class distribution
new_counts = {folder.name: len(list(folder.glob('*'))) for folder in balanced_path.iterdir() if folder.is_dir()}
print("\n‚úÖ Class Distribution AFTER balancing:\n", new_counts)

"""**Download the balanced dataset as ZIP**"""

# Zip the balanced folder
shutil.make_archive('balanced_dataset', 'zip', '/content/balanced_dataset')

# Download the zip file
from google.colab import files
files.download('balanced_dataset.zip')

import shutil # Import the shutil module to access the copy function
import os
# Optional: Save balanced dataset to new folders
balanced_dir = '/content/balanced_dataset'
if not os.path.exists(balanced_dir):
    os.makedirs(balanced_dir)

for cls in classes:
    os.makedirs(os.path.join(balanced_dir, cls), exist_ok=True)

for _, row in balanced_df.iterrows():
    # Assuming your DataFrame has a column named 'Filename' or 'Path'
    # that contains the path to the source image file.
    # Replace 'Filename' with the actual column name if it's different.
    # This section was unindented. Indenting fixes the error.
    source_path = row.get('Path', row['Filename'])  # Try 'Path' first, fallback to 'Filename'
    dest_path = os.path.join(balanced_dir, row['Class'], os.path.basename(source_path))
    #copyfile(source_path, dest_path) # Assuming 'copyfile' is imported.

"""**‚úÖ (3) Intensity Distribution**"""

# Intensity distribution by class
plt.figure(figsize=(10,6))
sns.barplot(data=df, x='Class', y='Mean_Intensity')
plt.title('Mean Intensity Distribution per Class')
plt.xlabel('Class')
plt.ylabel('Mean Pixel Intensity (Grayscale)')
plt.show()

# 1. Boxplot of intensities per class
sns.boxplot(x='Class', y='Mean_Intensity', data=df)
plt.title('Mean Intensity per Class')
plt.show()

# 2. Class distribution
sns.countplot(x='Class', data=df)
plt.title('Image Count per Class')
plt.show()

# 3. Correlation heatmap
sns.heatmap(df[['Width', 'Height', 'Aspect_Ratio', 'Mean_Intensity', 'Median_Intensity', 'Mode_Intensity']].corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

# 4. Grid of images per class
import random
fig, axes = plt.subplots(1, 3, figsize=(12, 4))
for i, label in enumerate(df['Class'].unique()):
    sample_file = random.choice(df[df['Class'] == label]['Filename'].values)
    path = os.path.join(data_dir, label, sample_file)
    img = Image.open(path)
    axes[i].imshow(img)
    axes[i].set_title(label)
    axes[i].axis('off')
plt.suptitle("Sample Images from Each Class")
plt.tight_layout()
plt.show()

"""üìê Why Check Aspect Ratio in Image Datasets?

‚ö†Ô∏è 1. Aspect Ratio Impacts Model Performance
Aspect ratio = Width / Height of the image.

If images across classes have very different shapes, your model might learn shape/size patterns instead of real features (e.g., tissue structures).

For example, if HCC images are mostly wide and Normal are tall, your model might cheat and learn that instead of learning actual liver cell patterns. That's called data leakage or bias.

üìä 2. Quality Check & Preprocessing
By plotting the aspect ratio (as you did with a violin plot), you're checking:

Are all images consistently shaped?

Are there outliers (very stretched or squished images)?

This helps you standardize image dimensions, like resizing to (224x224) or padding images without distorting them.

üîç 3. Violin Plot Insight
Your sns.violinplot() shows how the distribution of aspect ratios varies across HCC, CC, and Normal Liver.

If distributions are very different, you may consider:

Resizing all images while maintaining aspect ratio (with padding)

Or forcing a fixed aspect ratio (may lose detail)

‚ú® BONUS: Why You Also Checked Mean Intensity
Mean intensity gives an idea of brightness or tissue density.

Variations here can show differences in staining, scanner settings, or cell structure‚Äîuseful for further feature engineering.

‚úÖ In Short:
You checked aspect ratio to ensure image shape consistency, avoid biases or shortcuts in model learning, and to improve model generalization.
"""

# Aspect Ratio Distribution
plt.figure(figsize=(10,6))
sns.violinplot(data=df, x='Class', y='Aspect_Ratio', inner='box')
plt.title('Aspect Ratio Distribution per Class')
plt.xlabel('Class')
plt.ylabel('Width / Height')
plt.show()

# Insights
print("Aspect Ratio Summary:")
print(df.groupby('Class')['Aspect_Ratio'].describe())

print("\nMean Intensity Summary:")
print(df.groupby('Class')['Mean_Intensity'].describe())

"""**‚úÖ (5) Parameters For Analysis**

üí° Parameters Used in Histopathology EDA Parameter	Description

Width & Height	Dimensions of each image

Aspect Ratio	Width / Height, used to analyze resizing needs

Mean Intensity	Average grayscale intensity per image

Class	Label/category of image

Pixel Stats	Mean and StdDev of intensity and aspect ratio
"""

summary_stats = df.groupby('Class').agg({
    'Width': ['mean', 'std'],
    'Height': ['mean', 'std'],
    'Aspect_Ratio': ['mean', 'std'],
    'Mean_Intensity': ['mean', 'std']
}).round(2)

summary_stats.columns = ['_'.join(col) for col in summary_stats.columns]
summary_stats.reset_index(inplace=True)
print(summary_stats)

"""**üîç Additional Visualization (Optional)**"""

# Sample images per class
fig, axes = plt.subplots(1, 3, figsize=(15,5))
for ax, label in zip(axes, classes):
    class_dir = os.path.join(data_dir, label)
    sample_image = os.listdir(class_dir)[0]
    img_path = os.path.join(class_dir, sample_image)
    img = Image.open(img_path)
    ax.imshow(img)
    ax.set_title(label)
    ax.axis('off')
plt.suptitle("Sample Images per Class")
plt.show()

"""#DATA PREPROCESSING

Data preprocessing in deep learning refers to the steps taken to prepare raw input data into a suitable format for training a model. In this project, it involves resizing all histopathology images to a uniform size (224x224 pixels), normalizing pixel values to a range between 0 and 1, and applying data augmentation techniques like rotation, flipping, and zooming to artificially increase the diversity of the training set. It also includes batching the images to train the model efficiently and automatically assigning binary labels (e.g., 'normal' as 0 and 'damaged' as 1) based on the folder structure. These steps help the model learn better, avoid overfitting, and improve performance.

-------------------------  **Data Preprocessing Steps**  -----------------------
"""

# -------- Configuration --------
input_dir = "/content/balanced_dataset"  # üîÅ Replace with balance dataset directory (containing HCC, CC, NORMAL LIVER)
output_dir = "processed_dataset"

import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array
from tqdm import tqdm

# -------- Configuration --------
input_dir = "/content/balanced_dataset"  # Make sure this has 869 images per class
output_dir = "processed_dataset"
os.makedirs(output_dir, exist_ok=True)

classes = os.listdir(input_dir)
for cls in classes:
    os.makedirs(os.path.join(output_dir, cls), exist_ok=True)

# -------- Data Augmentation Config (just 1 variant) --------
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest'
)

# -------- Process Each Image --------
for cls in classes:
    class_path = os.path.join(input_dir, cls)
    save_path = os.path.join(output_dir, cls)

    for img_name in tqdm(os.listdir(class_path), desc=f"Processing {cls}"):
        img_path = os.path.join(class_path, img_name)

        # Step 1: Load image
        img = cv2.imread(img_path)
        if img is None:
            continue  # skip unreadable images
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Step 2: Save Original
        base_filename = os.path.splitext(img_name)[0]
        cv2.imwrite(os.path.join(save_path, f"{base_filename}_original.jpg"), img)

        # Step 3: Augment (only 1 variant)
        img_array = img_to_array(img_rgb) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        aug_iter = datagen.flow(img_array, batch_size=1)
        aug_image = next(aug_iter)[0]  # shape: (H, W, 3), scaled between 0-1
        aug_image_uint8 = (aug_image * 255).astype("uint8")

        # Step 4: Save augmented
        cv2.imwrite(os.path.join(save_path, f"{base_filename}_augmented.jpg"), cv2.cvtColor(aug_image_uint8, cv2.COLOR_RGB2BGR))

print("‚úÖ All images processed and saved with only 1 augmentation per original.")

import os
# Path to the processed dataset
processed_dir = "/content/processed_dataset"

# Dictionary to hold class-wise image counts
class_counts = {}

# Count images in each class folder
for cls in os.listdir(processed_dir):
    class_path = os.path.join(processed_dir, cls)
    if os.path.isdir(class_path):
        image_count = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png'))])
        class_counts[cls] = image_count

# Display class-wise counts
print("üì¶ Processed Image Counts per Class:")
for cls, count in class_counts.items():
    print(f"{cls}: {count} images")

# Total images
total_images = sum(class_counts.values())
print(f"\nüßÆ Total Processed Images: {total_images}")

import shutil

# Zip the folder
shutil.make_archive("processed_dataset", 'zip', "processed_dataset")